# 01. Hadoop HDFS í™˜ê²½ êµ¬ì¶•

**íƒœê·¸**: #hadoop #hdfs #docker #í™˜ê²½êµ¬ì¶• #hands-on
**ì†Œìš” ì‹œê°„**: 1-2ì‹œê°„
**ë‚œì´ë„**: ì´ˆê¸‰

## ëª©í‘œ

ì´ ë‹¨ê³„ì—ì„œëŠ” Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ í™˜ê²½ì— Hadoop HDFS í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] Hadoop Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì„±ê³µ
- [ ] HDFS ì›¹ UI (http://localhost:9870) ì ‘ì† ì„±ê³µ
- [ ] HDFS ê¸°ë³¸ ëª…ë ¹ì–´ ì‹¤í–‰ ê°€ëŠ¥

## ë°©ë²• 1: Docker Composeë¡œ Hadoop í´ëŸ¬ìŠ¤í„° êµ¬ì¶• (ê¶Œì¥)

### Step 1: Docker Compose íŒŒì¼ ìƒì„±

í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì— `docker-compose.yml` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```bash
mkdir -p ~/hadoop-practice
cd ~/hadoop-practice
```

`docker-compose.yml` ë‚´ìš©:

> **ì£¼ì˜**: Apple Silicon (M1/M2/M3) Macì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì•„ë˜ bde2020 ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. Intel Macì´ë‚˜ Linuxì—ì„œëŠ” apache/hadoop ì´ë¯¸ì§€ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ([í”Œë«í¼ë³„ ì£¼ì˜ì‚¬í•­](#í”Œë«í¼ë³„-ì£¼ì˜ì‚¬í•­) ì°¸ê³ )

```yaml
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    hostname: namenode
    ports:
      - "9870:9870"  # NameNode Web UI
      - "9000:9000"  # HDFS Port
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_replication=3
      - HDFS_CONF_dfs_permissions_enabled=false
    volumes:
      - namenode_data:/hadoop/dfs/name
    networks:
      - hadoop_network

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode1
    hostname: datanode1
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=3
    volumes:
      - datanode1_data:/hadoop/dfs/data
    networks:
      - hadoop_network
    depends_on:
      - namenode

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode2
    hostname: datanode2
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=3
    volumes:
      - datanode2_data:/hadoop/dfs/data
    networks:
      - hadoop_network
    depends_on:
      - namenode

  datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode3
    hostname: datanode3
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=3
    volumes:
      - datanode3_data:/hadoop/dfs/data
    networks:
      - hadoop_network
    depends_on:
      - namenode

volumes:
  namenode_data:
  datanode1_data:
  datanode2_data:
  datanode3_data:

networks:
  hadoop_network:
    driver: bridge
```

<details>
<summary><strong>Intel Mac / Linuxìš© ëŒ€ì•ˆ: apache/hadoop ì´ë¯¸ì§€</strong></summary>

Intel ê¸°ë°˜ Macì´ë‚˜ Linuxë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, apache/hadoop ê³µì‹ ì´ë¯¸ì§€ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤:

```yaml
services:
  namenode:
    image: apache/hadoop:3.3.6
    platform: linux/amd64  # Intel Macì˜ ê²½ìš° ëª…ì‹œ
    container_name: hadoop-namenode
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - "9870:9870"
      - "9000:9000"
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    volumes:
      - namenode_data:/tmp/hadoop-root/dfs/name
    networks:
      - hadoop_network

  # datanode1, datanode2, datanode3 ì„¤ì •ì€ ìœ„ì™€ ìœ ì‚¬
  # (ê° ì„œë¹„ìŠ¤ì— platform: linux/amd64 ì¶”ê°€)
```

</details>

### Step 2: Hadoop í´ëŸ¬ìŠ¤í„° ì‹œì‘

```bash
# í´ëŸ¬ìŠ¤í„° ì‹œì‘
docker-compose up -d

# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps
```

**ì˜ˆìƒ ì¶œë ¥**:
```
NAME                IMAGE               STATUS
hadoop-namenode     apache/hadoop:3.3.6 Up 2 minutes
hadoop-datanode1    apache/hadoop:3.3.6 Up 2 minutes
hadoop-datanode2    apache/hadoop:3.3.6 Up 2 minutes
hadoop-datanode3    apache/hadoop:3.3.6 Up 2 minutes
```

### Step 3: NameNode í¬ë§·

> **ì°¸ê³ **: bde2020 ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, NameNodeê°€ ìë™ìœ¼ë¡œ í¬ë§·ë©ë‹ˆë‹¤. ë³„ë„ì˜ í¬ë§· ì‘ì—…ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

apache/hadoop ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì—ë§Œ ì•„ë˜ ëª…ë ¹ì–´ë¡œ ìˆ˜ë™ í¬ë§·ì´ í•„ìš”í•©ë‹ˆë‹¤:

```bash
# NameNode ì»¨í…Œì´ë„ˆ ì ‘ì†
docker exec -it hadoop-namenode bash

# NameNode í¬ë§·
hdfs namenode -format

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
exit
docker-compose restart namenode
```

### Step 4: í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸

#### 4.1 ì›¹ UI ì ‘ì†
ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URL ì ‘ì†:
- **NameNode UI**: http://localhost:9870
- í™•ì¸ ì‚¬í•­:
  - Live Nodes: 3ê°œ (datanode1, datanode2, datanode3)
  - Dead Nodes: 0ê°œ
  - Configured Capacity > 0

#### 4.2 CLIë¡œ ìƒíƒœ í™•ì¸

```bash
# HDFS í´ëŸ¬ìŠ¤í„° ë¦¬í¬íŠ¸
docker exec hadoop-namenode hdfs dfsadmin -report

# íŒŒì¼ ì‹œìŠ¤í…œ í™•ì¸
docker exec hadoop-namenode hdfs dfs -ls /
```

**ì •ìƒ ì¶œë ¥ ì˜ˆì‹œ**:
```
Configured Capacity: 127718608896 (118.95 GB)
Present Capacity: 107501309952 (100.12 GB)
DFS Remaining: 107501293568 (100.12 GB)
...
Live datanodes (3):
```

## ë°©ë²• 2: ë‹¨ì¼ ì»¨í…Œì´ë„ˆë¡œ ê°„ë‹¨í•œ Pseudo-Distributed ëª¨ë“œ

ì‹œê°„ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ê°„ë‹¨íˆ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ë‹¤ë©´:

```bash
# ë‹¨ì¼ Hadoop ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name hadoop-standalone \
  -p 9870:9870 \
  -p 8088:8088 \
  -p 9000:9000 \
  apache/hadoop:3.3.6

# NameNode í¬ë§·
docker exec hadoop-standalone hdfs namenode -format

# Hadoop ì„œë¹„ìŠ¤ ì‹œì‘
docker exec hadoop-standalone bash -c "hdfs --daemon start namenode"
docker exec hadoop-standalone bash -c "hdfs --daemon start datanode"

# ìƒíƒœ í™•ì¸
docker exec hadoop-standalone hdfs dfsadmin -report
```

## ë°©ë²• 3: ë¡œì»¬ ë„¤ì´í‹°ë¸Œ ì„¤ì¹˜ (ì„ íƒ ì‚¬í•­)

### macOS ì„¤ì¹˜

```bash
# Homebrewë¡œ Hadoop ì„¤ì¹˜
brew install hadoop

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export HADOOP_HOME=/usr/local/Cellar/hadoop/3.3.6/libexec
export PATH=$PATH:$HADOOP_HOME/bin

# ì„¤ì • íŒŒì¼ ìˆ˜ì •
cd $HADOOP_HOME/etc/hadoop

# core-site.xml ìˆ˜ì •
cat <<EOF > core-site.xml
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
  </property>
</configuration>
EOF

# hdfs-site.xml ìˆ˜ì •
cat <<EOF > hdfs-site.xml
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
EOF

# NameNode í¬ë§·
hdfs namenode -format

# HDFS ì‹œì‘
start-dfs.sh
```

### Ubuntu/Linux ì„¤ì¹˜

```bash
# Java ì„¤ì¹˜ (í•„ìˆ˜)
sudo apt update
sudo apt install openjdk-11-jdk -y

# Hadoop ë‹¤ìš´ë¡œë“œ
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
tar -xzf hadoop-3.3.6.tar.gz
sudo mv hadoop-3.3.6 /usr/local/hadoop

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
echo 'export HADOOP_HOME=/usr/local/hadoop' >> ~/.bashrc
echo 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' >> ~/.bashrc
source ~/.bashrc

# core-site.xml ë° hdfs-site.xml ì„¤ì • (macOSì™€ ë™ì¼)
# NameNode í¬ë§· ë° ì‹œì‘
hdfs namenode -format
start-dfs.sh
```

## ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

í™˜ê²½ êµ¬ì¶•ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

### í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰**: `docker ps`ë¡œ hadoop-namenode, hadoop-datanode* ì»¨í…Œì´ë„ˆ í™•ì¸
- [ ] **ì›¹ UI ì ‘ì†**: http://localhost:9870 ì ‘ì† ì„±ê³µ
- [ ] **Live Nodes í™•ì¸**: ì›¹ UIì—ì„œ Live Nodesê°€ 3ê°œ í‘œì‹œ
- [ ] **CLI ëª…ë ¹ì–´ ì‹¤í–‰**: `docker exec hadoop-namenode hdfs dfs -ls /` ì‹¤í–‰ ì„±ê³µ
- [ ] **HDFS ë¦¬í¬íŠ¸**: `docker exec hadoop-namenode hdfs dfsadmin -report` ì •ìƒ ì¶œë ¥

### ì„ íƒ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ë¡œê·¸ í™•ì¸**: `docker logs hadoop-namenode` ì—ëŸ¬ ì—†ì´ ì‹¤í–‰ í™•ì¸
- [ ] **ë””ë ‰í† ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸**: `hdfs dfs -mkdir /test` ì‹¤í–‰ ë° í™•ì¸
- [ ] **íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸**: ê°„ë‹¨í•œ íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ ì„±ê³µ

## ë¡œì»¬ í™˜ê²½ vs í”„ë¡œë•ì…˜ í™˜ê²½

### âš ï¸ ë¡œì»¬ Docker í™˜ê²½ì˜ ì œí•œì‚¬í•­

ë¡œì»¬ Docker í™˜ê²½ì—ì„œ Hadoopì„ ì‹¤í–‰í•  ë•ŒëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ê³¼ ë‹¤ìŒê³¼ ê°™ì€ ì¤‘ìš”í•œ ì°¨ì´ì ì´ ìˆìŠµë‹ˆë‹¤:

#### 1. ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ì¤‘ë³µ ì¹´ìš´íŠ¸

**í˜„ìƒ:**
```bash
docker exec hadoop-namenode hdfs dfsadmin -report
# ì¶œë ¥:
# Configured Capacity: 287.47 GB
# Live datanodes (3):
#   - DataNode 1: 95.82 GB
#   - DataNode 2: 95.82 GB
#   - DataNode 3: 95.82 GB
```

**ë¬¸ì œì :**
- ëª¨ë“  DataNodeê°€ **ê°™ì€ í˜¸ìŠ¤íŠ¸ ë””ìŠ¤í¬**ë¥¼ ê³µìœ 
- ê° DataNodeê°€ í˜¸ìŠ¤íŠ¸ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ê³µê°„ì„ ë…ë¦½ì ìœ¼ë¡œ ë³´ê³ 
- **ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ìš©ëŸ‰**: ~95 GB (287 GBê°€ ì•„ë‹˜!)
- 3ê°œ DataNodeê°€ ìš©ëŸ‰ì„ ê³µìœ í•˜ë¯€ë¡œ ì¤‘ë³µ ì¹´ìš´íŠ¸ë¨

**í™•ì¸ ë°©ë²•:**
```bash
# í˜¸ìŠ¤íŠ¸ì˜ ì‹¤ì œ ë””ìŠ¤í¬ ìš©ëŸ‰ í™•ì¸
df -h /

# Docker ë³¼ë¥¨ ìœ„ì¹˜ í™•ì¸
docker volume inspect hadoop-hands-on_namenode_data
# ëª¨ë“  ë³¼ë¥¨ì´ /var/lib/docker/volumes/ ì•„ë˜ì— ìˆìŒ
```

**ë¹„êµ:**

| í™˜ê²½ | ìŠ¤í† ë¦¬ì§€ êµ¬ì„± | ì‹¤ì œ ìš©ëŸ‰ |
|------|--------------|----------|
| **ë¡œì»¬ Docker** | ëª¨ë“  ë³¼ë¥¨ì´ í˜¸ìŠ¤íŠ¸ ë””ìŠ¤í¬ ê³µìœ  | ~95 GB (ì¤‘ë³µ ì¹´ìš´íŠ¸) |
| **í”„ë¡œë•ì…˜** | ê° DataNodeê°€ ë…ë¦½ì ì¸ ë¬¼ë¦¬ ë””ìŠ¤í¬ | 287 GB (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥) |

#### 2. ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥

**ë¡œì»¬ Docker:**
- ê°€ìƒ ë„¤íŠ¸ì›Œí¬ (Docker bridge)
- ëª¨ë“  ì»¨í…Œì´ë„ˆê°€ ê°™ì€ í˜¸ìŠ¤íŠ¸ì—ì„œ ì‹¤í–‰
- ë„¤íŠ¸ì›Œí¬ I/Oê°€ ë©”ëª¨ë¦¬ ìˆ˜ì¤€ìœ¼ë¡œ ë¹ ë¦„

**í”„ë¡œë•ì…˜:**
- ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ (1Gbps ~ 100Gbps)
- ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œì™€ ëŒ€ì—­í­ ì œì•½ ì¡´ì¬
- ë„¤íŠ¸ì›Œí¬ ì¥ì•  ê°€ëŠ¥ì„±

#### 3. ë¦¬ì†ŒìŠ¤ ê²©ë¦¬

**ë¡œì»¬ Docker:**
- CPUì™€ ë©”ëª¨ë¦¬ë¥¼ í˜¸ìŠ¤íŠ¸ì™€ ê³µìœ 
- ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì˜í–¥ì„ ë°›ìŒ
- Docker Desktop ì„¤ì •ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ì œí•œ

**í”„ë¡œë•ì…˜/Kubernetes:**
- ê° ë…¸ë“œê°€ ë…ë¦½ì ì¸ ì„œë²„
- CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ê°€ ë¬¼ë¦¬ì ìœ¼ë¡œ ê²©ë¦¬
- Resource Quotaì™€ Limitìœ¼ë¡œ ê´€ë¦¬

### ğŸ“‹ í™˜ê²½ë³„ ì‚¬ìš© ì‚¬ë¡€

| í™˜ê²½ | ì í•©í•œ ìš©ë„ | ì œí•œì‚¬í•­ |
|------|-----------|---------|
| **ë¡œì»¬ Docker** | - í•™ìŠµ ë° ì‹¤ìŠµ<br>- ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸<br>- ê°œë°œ í™˜ê²½ | - ì‹¤ì œ ìš©ëŸ‰ ì œí•œ<br>- ì„±ëŠ¥ ì¸¡ì • ë¶€ì •í™•<br>- ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ ì œí•œì  |
| **í´ë¼ìš°ë“œ (ì˜ˆì •)** | - ì¤‘ì†Œ ê·œëª¨ ìš´ì˜<br>- CI/CD íŒŒì´í”„ë¼ì¸ | - ë¹„ìš© ë°œìƒ<br>- ë„¤íŠ¸ì›Œí¬ ì„¤ì • í•„ìš” |
| **Kubernetes (ì˜ˆì •)** | - ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜<br>- ìë™ ìŠ¤ì¼€ì¼ë§<br>- ê³ ê°€ìš©ì„± | - ë³µì¡í•œ ì„¤ì •<br>- ìš´ì˜ ë…¸í•˜ìš° í•„ìš” |

### ğŸš€ í”„ë¡œë•ì…˜ í™˜ê²½ ê°€ì´ë“œ (ì˜ˆì •)

í–¥í›„ ë‹¤ìŒ ê°€ì´ë“œê°€ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤:

- **í´ë¼ìš°ë“œ í™˜ê²½ êµ¬ì¶•** (AWS, GCP, Azure)
  - ê° DataNodeê°€ ë…ë¦½ì ì¸ VM ë˜ëŠ” ë¬¼ë¦¬ ì„œë²„ì— ë°°í¬
  - ì‹¤ì œ ë¶„ì‚° ìŠ¤í† ë¦¬ì§€ í™œìš©
  - ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ ë° ë³´ì•ˆ ì„¤ì •

- **Kubernetes ê¸°ë°˜ ë°°í¬**
  - StatefulSetìœ¼ë¡œ DataNode ê´€ë¦¬
  - PersistentVolumeìœ¼ë¡œ ë…ë¦½ì ì¸ ìŠ¤í† ë¦¬ì§€ í• ë‹¹
  - Horizontal Pod Autoscaling
  - ì¥ì•  ë³µêµ¬ ìë™í™”

### ğŸ’¡ ë¡œì»¬ í™˜ê²½ ì‚¬ìš© ì‹œ ê¶Œì¥ì‚¬í•­

1. **ìš©ëŸ‰ ê³„íš**:
   - ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ê³µê°„ì˜ 70% ì´í•˜ë§Œ ì‚¬ìš©
   - í° íŒŒì¼ ì—…ë¡œë“œ ì „ `df -h /` ë¡œ ê³µê°„ í™•ì¸

2. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**:
   - ë¡œì»¬ í™˜ê²½ì˜ ì„±ëŠ¥ì€ ì°¸ê³ ìš©
   - ì‹¤ì œ ì„±ëŠ¥ì€ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì¸¡ì •

3. **í•™ìŠµ ëª©ì **:
   - HDFS ê°œë…ê³¼ ëª…ë ¹ì–´ ìµíˆê¸°
   - Replication ë™ì‘ ì›ë¦¬ ì´í•´
   - ê¸°ë³¸ ìš´ì˜ ê¸°ìˆ  ìŠµë“

## í”Œë«í¼ë³„ ì£¼ì˜ì‚¬í•­

### Apple Silicon (M1/M2/M3) Mac

**ê¶Œì¥ ì´ë¯¸ì§€**: `bde2020/hadoop-namenode` ë° `bde2020/hadoop-datanode`

**ì´ìœ **:
- apache/hadoop ê³µì‹ ì´ë¯¸ì§€ëŠ” ARM64 ì•„í‚¤í…ì²˜ë¥¼ ì™„ì „íˆ ì§€ì›í•˜ì§€ ì•ŠìŒ
- Segmentation Fault ë˜ëŠ” ì„±ëŠ¥ ì €í•˜ ë°œìƒ ê°€ëŠ¥
- bde2020 ì´ë¯¸ì§€ëŠ” ë©€í‹° ì•„í‚¤í…ì²˜ë¥¼ ì§€ì›í•˜ì—¬ ì•ˆì •ì 

**ë°œìƒ ê°€ëŠ¥í•œ ë¬¸ì œ**:
```
/opt/starter.sh: line 156:    28 Segmentation fault (core dumped)
```

### Intel Mac / Linux

**ê¶Œì¥ ì´ë¯¸ì§€**: `apache/hadoop:3.3.6` ë˜ëŠ” `bde2020` ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥

**apache/hadoop ì´ë¯¸ì§€ ì‚¬ìš© ì‹œ**:
- `platform: linux/amd64` ì„¤ì • ê¶Œì¥
- NameNode ìˆ˜ë™ í¬ë§· í•„ìš”

## ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: Apple Siliconì—ì„œ Segmentation Fault

**ì¦ìƒ**:
```bash
docker logs hadoop-namenode
# ì¶œë ¥:
# /opt/starter.sh: line 156:    28 Segmentation fault (core dumped)
```

**ì›ì¸**: apache/hadoop ì´ë¯¸ì§€ê°€ ARM64ë¥¼ ì™„ì „íˆ ì§€ì›í•˜ì§€ ì•ŠìŒ

**í•´ê²°**:
1. bde2020 ì´ë¯¸ì§€ë¡œ ë³€ê²½ (ê¶Œì¥)
2. ë˜ëŠ” Rosetta 2ë¥¼ ì‚¬ìš©í•œ ì—ë®¬ë ˆì´ì…˜ (ëŠë¦´ ìˆ˜ ìˆìŒ)

### ë¬¸ì œ 2: NameNode í¬ë§· ì‹¤íŒ¨

**ì¦ìƒ**:
```bash
ERROR: Cannot create directory /tmp/hadoop-root/dfs/name/current
java.io.IOException: Cannot create directory
```

**ì›ì¸**:
- ê¶Œí•œ ë¬¸ì œ ë˜ëŠ” ë³¼ë¥¨ ë§ˆìš´íŠ¸ ì‹¤íŒ¨
- apache/hadoop ì´ë¯¸ì§€ ì‚¬ìš© ì‹œ ë°œìƒ ê°€ëŠ¥

**í•´ê²°**:
```bash
# 1. ë³¼ë¥¨ ì™„ì „ ì‚­ì œ í›„ ì¬ì‹œì‘
docker-compose down -v
docker-compose up -d

# 2. bde2020 ì´ë¯¸ì§€ë¡œ ë³€ê²½ (ìë™ í¬ë§·)
```

### ë¬¸ì œ 3: í¬íŠ¸ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘

**ì¦ìƒ**:
```
Error: Port 9870 is already in use
```

**í•´ê²°**:
```bash
# í¬íŠ¸ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸
lsof -i :9870

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>

# ë˜ëŠ” docker-compose.ymlì—ì„œ í¬íŠ¸ ë³€ê²½
ports:
  - "19870:9870"
```

### ë¬¸ì œ 4: DataNodeê°€ ì—°ê²°ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**: ì›¹ UIì—ì„œ Live Nodesê°€ 0ê°œ

**í•´ê²°**:
```bash
# NameNode ë¡œê·¸ í™•ì¸
docker logs hadoop-namenode

# DataNode ë¡œê·¸ í™•ì¸
docker logs hadoop-datanode1

# ë„¤íŠ¸ì›Œí¬ í™•ì¸
docker network inspect hadoop-hands-on_hadoop_network

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose restart
```

### ë¬¸ì œ 5: ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ**:
```
Container exited with code 137
```

**í•´ê²°**:
- Docker Desktop â†’ Settings â†’ Resources â†’ Memoryë¥¼ ìµœì†Œ 4GBë¡œ ì¦ê°€

### ë¬¸ì œ 6: NameNode "safe mode" ìƒíƒœ

**ì¦ìƒ**:
```
Name node is in safe mode
```

**í•´ê²°**:
```bash
# Safe mode ìˆ˜ë™ í•´ì œ
docker exec hadoop-namenode hdfs dfsadmin -safemode leave

# Safe mode ìƒíƒœ í™•ì¸
docker exec hadoop-namenode hdfs dfsadmin -safemode get
```

## ìœ ìš©í•œ ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# í´ëŸ¬ìŠ¤í„° ì‹œì‘/ì¢…ë£Œ
docker-compose up -d          # ì‹œì‘
docker-compose down           # ì¢…ë£Œ
docker-compose restart        # ì¬ì‹œì‘

# ë¡œê·¸ í™•ì¸
docker logs -f hadoop-namenode    # NameNode ë¡œê·¸ (ì‹¤ì‹œê°„)
docker logs -f hadoop-datanode1   # DataNode1 ë¡œê·¸ (ì‹¤ì‹œê°„)

# ì»¨í…Œì´ë„ˆ ì ‘ì†
docker exec -it hadoop-namenode bash

# HDFS ìƒíƒœ í™•ì¸
docker exec hadoop-namenode hdfs dfsadmin -report
docker exec hadoop-namenode hdfs dfsadmin -safemode get

# íŒŒì¼ ì‹œìŠ¤í…œ í™•ì¸
docker exec hadoop-namenode hdfs dfs -ls /
docker exec hadoop-namenode hdfs dfs -df -h
```

## í™˜ê²½ ì •ë¦¬ (ì‹¤ìŠµ ì¢…ë£Œ ì‹œ)

```bash
# ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ë° ì‚­ì œ
docker-compose down

# ë³¼ë¥¨ê¹Œì§€ ì™„ì „ ì‚­ì œ (ì£¼ì˜: ëª¨ë“  ë°ì´í„° ì†ì‹¤)
docker-compose down -v

# ì´ë¯¸ì§€ ì‚­ì œ
docker rmi bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
docker rmi bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
# ë˜ëŠ” apache/hadoop ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ ê²½ìš°
# docker rmi apache/hadoop:3.3.6
```

## ë‹¤ìŒ ë‹¨ê³„

í™˜ê²½ êµ¬ì¶•ì´ ì™„ë£Œë˜ì—ˆë‹¤ë©´ HDFS ê¸°ë³¸ ëª…ë ¹ì–´ë¥¼ ì‹¤ìŠµí•´ë³´ì„¸ìš”:
â†’ **[02-ê¸°ë³¸ëª…ë ¹ì–´ì‹¤ìŠµ.md](./02-ê¸°ë³¸ëª…ë ¹ì–´ì‹¤ìŠµ.md)**

---

**ì‘ì„±ì¼**: 2025-11-17
**ìµœì¢… ìˆ˜ì •**: 2025-11-17
