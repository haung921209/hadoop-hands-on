# 04. HDFS 성능 및 장애 테스트

**태그**: #hadoop #hdfs #performance #fault-tolerance #testing #hands-on
**소요 시간**: 3-5시간
**난이도**: 고급

## 목표

HDFS의 성능 특성과 장애 복구 메커니즘을 실제로 테스트하고 이해합니다.

**완료 기준**:
- [ ] 읽기/쓰기 성능 벤치마크 수행 완료
- [ ] DataNode 장애 시뮬레이션 및 복구 확인
- [ ] NameNode 상태 모니터링 가능
- [ ] Replication 동작 검증 완료
- [ ] 네트워크 부하 테스트 완료

## 준비 사항

```bash
# Hadoop 클러스터 상태 확인
docker exec hadoop-namenode hdfs dfsadmin -report

# 테스트 디렉토리 생성
hdfs dfs -mkdir -p /test/performance
hdfs dfs -mkdir -p /test/fault-tolerance
```

---

## Part 1: 성능 벤치마크

### 테스트 1.1: TestDFSIO - 기본 I/O 성능 측정

TestDFSIO는 Hadoop에 내장된 벤치마크 도구입니다.

#### 쓰기 성능 테스트

```bash
# 10개의 파일, 각 100MB 크기로 쓰기 테스트
docker exec hadoop-namenode bash -c "hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 100MB"

# 결과 확인
# - Throughput mb/sec
# - Average IO rate mb/sec
# - IO rate std deviation
```

**예상 출력 분석**:
```
----- TestDFSIO ----- : write
           Date & time: Mon Nov 17 10:30:00 UTC 2025
       Number of files: 10
Total MBytes processed: 1000.0
     Throughput mb/sec: 45.23
Average IO rate mb/sec: 47.15
 IO rate std deviation: 8.32
    Test exec time sec: 28.45
```

**핵심 메트릭**:
- **Throughput**: 전체 처리량 (높을수록 좋음)
- **Average IO rate**: 평균 I/O 속도
- **Std deviation**: 표준 편차 (낮을수록 일관성 있음)

#### 읽기 성능 테스트

```bash
# 동일한 파일들을 읽는 테스트
docker exec hadoop-namenode bash -c "hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 100MB"

# 결과 비교
# 일반적으로 읽기 속도가 쓰기보다 빠름
```

#### 테스트 데이터 정리

```bash
# 벤치마크 데이터 삭제
docker exec hadoop-namenode bash -c "hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar TestDFSIO -clean"

# 확인
hdfs dfs -ls /benchmarks
```

### 테스트 1.2: 대용량 파일 업로드 성능

실제 시나리오에 가까운 대용량 파일 업로드 테스트를 수행합니다.

```bash
# 1GB 파일 생성
dd if=/dev/zero of=/tmp/1gb_file.bin bs=1M count=1024

# 시간 측정하며 업로드
time docker exec hadoop-namenode hdfs dfs -put /tmp/1gb_file.bin /test/performance/

# 결과 예시:
# real    0m15.234s
# user    0m2.123s
# sys     0m1.456s

# 속도 계산: 1024 MB / 15.234 s ≈ 67.2 MB/s
```

### 테스트 1.3: 소용량 파일 대량 업로드

```bash
# 10,000개의 작은 파일 생성
mkdir -p /tmp/small_files
for i in {1..10000}; do
    echo "Small file $i" > /tmp/small_files/file_${i}.txt
done

# 시간 측정하며 업로드
time docker exec hadoop-namenode hdfs dfs -put /tmp/small_files/* /test/performance/small/

# HDFS의 "small files problem" 확인
# - NameNode 메모리 사용량 증가
# - 메타데이터 오버헤드
```

**Small Files Problem 분석**:
```bash
# NameNode 메모리 사용량 확인
docker exec hadoop-namenode hdfs dfsadmin -report | grep -A 5 "Name Node"

# 파일 개수 vs 디스크 사용량 비교
hdfs dfs -count -h /test/performance/
```

### 테스트 1.4: 동시 접근 성능 (멀티스레드)

```bash
# 병렬 업로드 스크립트
cat <<'EOF' > /tmp/parallel_upload.sh
#!/bin/bash

for i in {1..5}; do
    (
        dd if=/dev/zero of=/tmp/parallel_${i}.bin bs=1M count=200
        docker exec hadoop-namenode hdfs dfs -put /tmp/parallel_${i}.bin /test/performance/
        echo "Thread $i completed"
    ) &
done

wait
echo "All parallel uploads completed"
EOF

chmod +x /tmp/parallel_upload.sh
time /tmp/parallel_upload.sh

# 단일 스레드와 비교하여 처리량 증가 확인
```

### 테스트 1.5: Replication Factor별 성능 비교

```bash
# 같은 크기의 파일로 replication factor별 성능 테스트
dd if=/dev/zero of=/tmp/test_file.bin bs=1M count=500

# Replication 1
time docker exec hadoop-namenode bash -c "hdfs dfs -put /tmp/test_file.bin /test/performance/rep1.bin && hdfs dfs -setrep 1 /test/performance/rep1.bin"

# Replication 2
time docker exec hadoop-namenode bash -c "hdfs dfs -put /tmp/test_file.bin /test/performance/rep2.bin && hdfs dfs -setrep 2 /test/performance/rep2.bin"

# Replication 3
time docker exec hadoop-namenode bash -c "hdfs dfs -put /tmp/test_file.bin /test/performance/rep3.bin && hdfs dfs -setrep 3 /test/performance/rep3.bin"

# 결과 비교
# - Replication factor가 높을수록 쓰기 시간 증가
# - 읽기 성능은 replication이 높을수록 유리 (여러 노드에서 병렬 읽기 가능)
```

---

## Part 2: 장애 테스트 및 복구

### 테스트 2.1: DataNode 장애 시뮬레이션

#### Step 1: 테스트 데이터 준비

```bash
# 테스트 파일 생성 (replication=3)
echo "Critical data for fault tolerance test" > /tmp/critical_data.txt
hdfs dfs -put /tmp/critical_data.txt /test/fault-tolerance/

# Replication factor 확인
hdfs dfs -setrep 3 /test/fault-tolerance/critical_data.txt
hdfs dfs -ls /test/fault-tolerance/

# 블록 위치 확인
hdfs fsck /test/fault-tolerance/critical_data.txt -files -blocks -locations
```

**예상 출력**:
```
/test/fault-tolerance/critical_data.txt 42 bytes, 1 block(s):
 0. BP-xxx:blk_1073741825 len=42 Live_repl=3
  [DatanodeInfoWithStorage[datanode1:9866]]
  [DatanodeInfoWithStorage[datanode2:9866]]
  [DatanodeInfoWithStorage[datanode3:9866]]
```

#### Step 2: DataNode 중지

```bash
# datanode1 컨테이너 중지
docker stop hadoop-datanode1

# 클러스터 상태 확인
docker exec hadoop-namenode hdfs dfsadmin -report

# Dead Nodes 확인 (몇 분 소요될 수 있음)
# - Live Nodes: 2 (datanode2, datanode3)
# - Dead Nodes: 1 (datanode1)
```

#### Step 3: 데이터 접근 가능 여부 확인

```bash
# 파일 읽기 (정상 동작해야 함)
hdfs dfs -cat /test/fault-tolerance/critical_data.txt

# 결과: "Critical data for fault tolerance test"
# → 2개의 replica만으로도 데이터 접근 가능!
```

#### Step 4: Under-Replicated 블록 확인

```bash
# 파일 시스템 체크
hdfs fsck /test/fault-tolerance/ -files -blocks

# Under-replicated blocks: 1
# (목표는 3개인데 현재 2개만 살아있음)
```

**예상 출력**:
```
Status: HEALTHY
 Total size:    42 B
 Total files:   1
 Total blocks (validated):      1 (avg. block size 42 B)
 Minimally replicated blocks:   1 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       1 (100.0 %)  ← 주목!
 Mis-replicated blocks:         0 (0.0 %)
```

#### Step 5: 자동 복구 관찰

```bash
# NameNode는 자동으로 under-replicated 블록을 복구하려고 시도
# 하지만 DataNode가 2개뿐이므로 replication=3 달성 불가

# 일정 시간 대기 후 다시 확인
sleep 60
hdfs fsck /test/fault-tolerance/critical_data.txt -files -blocks -locations

# Live_repl=2로 유지됨 (DataNode가 2개뿐이므로)
```

#### Step 6: DataNode 복구

```bash
# datanode1 재시작
docker start hadoop-datanode1

# 클러스터 상태 확인 (재연결까지 1-2분 소요)
docker exec hadoop-namenode hdfs dfsadmin -report

# Live Nodes: 3 확인
```

#### Step 7: Replication 복구 확인

```bash
# 자동으로 replication=3 복구됨
# 몇 분 대기 후 확인
sleep 120

hdfs fsck /test/fault-tolerance/critical_data.txt -files -blocks -locations

# Live_repl=3로 복구 확인!
```

### 테스트 2.2: 여러 DataNode 동시 장애

```bash
# 2개의 DataNode 동시 중지
docker stop hadoop-datanode1 hadoop-datanode2

# 클러스터 상태 확인
docker exec hadoop-namenode hdfs dfsadmin -report
# Live Nodes: 1 (datanode3만 살아있음)

# 데이터 접근 (여전히 가능!)
hdfs dfs -cat /test/fault-tolerance/critical_data.txt

# 파일 시스템 상태 (Critical!)
hdfs fsck / -files -blocks
# Under-replicated blocks 급증
```

**복구**:
```bash
# DataNode 재시작
docker start hadoop-datanode1 hadoop-datanode2

# 클러스터 정상화 대기
sleep 180

# 복구 확인
hdfs dfsadmin -report
hdfs fsck / -files -blocks
```

### 테스트 2.3: NameNode Safe Mode

Safe Mode는 NameNode가 시작 시 또는 문제 발생 시 진입하는 보호 모드입니다.

```bash
# Safe mode 강제 진입
docker exec hadoop-namenode hdfs dfsadmin -safemode enter

# Safe mode 상태 확인
docker exec hadoop-namenode hdfs dfsadmin -safemode get
# Safe mode is ON

# 쓰기 시도 (실패해야 함)
hdfs dfs -put /tmp/test.txt /test/
# Error: Name node is in safe mode
```

**Safe Mode에서 가능한 작업**:
- ✅ 읽기 (cat, get)
- ❌ 쓰기 (put, mkdir, rm)
- ✅ 조회 (ls, df, du)

```bash
# Safe mode 해제
docker exec hadoop-namenode hdfs dfsadmin -safemode leave

# 확인
docker exec hadoop-namenode hdfs dfsadmin -safemode get
# Safe mode is OFF
```

### 테스트 2.4: 디스크 용량 부족 시뮬레이션

```bash
# DataNode 디스크 사용량 확인
hdfs dfs -df -h

# 대용량 파일로 디스크 채우기
for i in {1..100}; do
    dd if=/dev/zero of=/tmp/filler_${i}.bin bs=1M count=100
    hdfs dfs -put /tmp/filler_${i}.bin /test/disk_full/ 2>/dev/null || break
done

# 디스크 용량 초과 시 발생하는 에러 확인
# Error: No space left on device

# 클러스터 상태 확인
hdfs dfsadmin -report
# DFS Remaining 확인
```

**정리**:
```bash
# 테스트 파일 삭제
hdfs dfs -rm -r /test/disk_full
```

---

## Part 3: Replication 동작 검증

### 테스트 3.1: Replication Pipeline 관찰

```bash
# 큰 파일로 replication 과정 관찰
dd if=/dev/zero of=/tmp/large_replication_test.bin bs=1M count=500

# 업로드 중 로그 모니터링
docker logs -f hadoop-namenode &
LOGS_PID=$!

# 파일 업로드
hdfs dfs -put /tmp/large_replication_test.bin /test/replication/

# 로그 중지
kill $LOGS_PID

# 블록 위치 확인
hdfs fsck /test/replication/large_replication_test.bin -files -blocks -locations
```

### 테스트 3.2: Replication Factor 변경 시 동작

```bash
# 파일 생성
echo "Replication test data" > /tmp/rep_change.txt
hdfs dfs -put /tmp/rep_change.txt /test/replication/

# 초기 replication=3
hdfs dfs -setrep 3 /test/replication/rep_change.txt
sleep 10
hdfs fsck /test/replication/rep_change.txt -files -blocks -locations
# Live_repl=3 확인

# Replication을 5로 증가 (하지만 DataNode가 3개뿐)
hdfs dfs -setrep 5 /test/replication/rep_change.txt
sleep 10
hdfs fsck /test/replication/rep_change.txt -files -blocks -locations
# Live_repl=3 (최대값)

# Replication을 1로 감소
hdfs dfs -setrep 1 /test/replication/rep_change.txt
sleep 10
hdfs fsck /test/replication/rep_change.txt -files -blocks -locations
# Live_repl=1 확인 (나머지 2개 replica 삭제됨)
```

### 테스트 3.3: Over-Replication 시뮬레이션

```bash
# Replication=3 파일 생성
echo "Over-replication test" > /tmp/over_rep.txt
hdfs dfs -put /tmp/over_rep.txt /test/replication/
hdfs dfs -setrep 3 /test/replication/over_rep.txt

# 블록 위치 확인
hdfs fsck /test/replication/over_rep.txt -files -blocks -locations

# Replication을 2로 감소
hdfs dfs -setrep 2 /test/replication/over_rep.txt

# Over-replicated 블록 발생 (잠시 동안)
# NameNode가 자동으로 여분의 replica 삭제
sleep 30
hdfs fsck / -files -blocks
# Over-replicated blocks: 0 (정리됨)
```

---

## Part 4: 모니터링 및 메트릭

### 테스트 4.1: HDFS 웹 UI 메트릭 확인

브라우저에서 http://localhost:9870 접속 후 다음 항목 확인:

1. **Overview 탭**:
   - Configured Capacity
   - DFS Used
   - Non DFS Used
   - DFS Remaining

2. **Datanodes 탭**:
   - Live Nodes
   - Dead Nodes
   - Decommissioning Nodes
   - 각 DataNode별 사용량

3. **Utilities → Browse the file system**:
   - 파일 탐색
   - 블록 정보 확인

### 테스트 4.2: CLI로 메트릭 수집

```bash
# 전체 클러스터 리포트
hdfs dfsadmin -report

# JSON 형식으로 출력 (파싱 가능)
hdfs dfsadmin -report -json > /tmp/hdfs_report.json
cat /tmp/hdfs_report.json | jq '.'

# 파일 시스템 통계
hdfs dfs -df -h
hdfs dfs -du -s -h /

# 블록 통계
hdfs fsck / -files -blocks | grep "Total blocks"
```

### 테스트 4.3: 성능 메트릭 스크립트

`hdfs_metrics.sh`:

```bash
#!/bin/bash

echo "=== HDFS Cluster Metrics ==="
echo "Timestamp: $(date)"
echo ""

# 1. 클러스터 용량
echo "--- Capacity ---"
hdfs dfs -df -h

echo ""

# 2. Live/Dead Nodes
echo "--- Node Status ---"
LIVE_NODES=$(docker exec hadoop-namenode hdfs dfsadmin -report | grep -A 1 "Live datanodes" | tail -1 | awk '{print $1}')
DEAD_NODES=$(docker exec hadoop-namenode hdfs dfsadmin -report | grep -A 1 "Dead datanodes" | tail -1 | awk '{print $1}')
echo "Live Nodes: ${LIVE_NODES}"
echo "Dead Nodes: ${DEAD_NODES}"

echo ""

# 3. 파일 시스템 상태
echo "--- File System Health ---"
TOTAL_FILES=$(hdfs fsck / -files | grep "Total files" | awk '{print $3}')
TOTAL_BLOCKS=$(hdfs fsck / -files -blocks | grep "Total blocks" | awk '{print $3}')
UNDER_REPLICATED=$(hdfs fsck / -files -blocks | grep "Under-replicated blocks" | awk '{print $3}')
echo "Total Files: ${TOTAL_FILES}"
echo "Total Blocks: ${TOTAL_BLOCKS}"
echo "Under-replicated: ${UNDER_REPLICATED}"

echo ""
echo "=== End of Report ==="
```

실행:
```bash
chmod +x hdfs_metrics.sh
./hdfs_metrics.sh
```

---

## Part 5: 부하 테스트

### 테스트 5.1: NNBench - NameNode 부하 테스트

```bash
# NameNode에 대량의 메타데이터 작업 수행
docker exec hadoop-namenode bash -c "hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar NNBench \
  -operation create_write \
  -maps 4 \
  -reduces 2 \
  -blockSize 1 \
  -bytesToWrite 0 \
  -numberOfFiles 1000 \
  -replicationFactorPerFile 3 \
  -baseDir /benchmarks/NNBench"

# 결과 분석
# - Number of files: 1000
# - Throughput (ops/s)
# - Average time per operation
```

### 테스트 5.2: 동시 읽기/쓰기 테스트

```bash
# 스크립트 작성
cat <<'EOF' > /tmp/concurrent_test.sh
#!/bin/bash

# 5개의 쓰기 작업
for i in {1..5}; do
    (
        dd if=/dev/urandom of=/tmp/write_${i}.bin bs=1M count=100
        docker exec hadoop-namenode hdfs dfs -put /tmp/write_${i}.bin /test/concurrent/write_${i}.bin
    ) &
done

# 5개의 읽기 작업
for i in {1..5}; do
    (
        docker exec hadoop-namenode hdfs dfs -get /test/performance/rep1.bin /tmp/read_${i}.bin
    ) &
done

wait
echo "Concurrent test completed"
EOF

chmod +x /tmp/concurrent_test.sh
time /tmp/concurrent_test.sh
```

---

## 실습 과제

### 과제 1: 성능 벤치마크 리포트 작성

다음 테스트를 수행하고 결과를 비교 분석하세요:
1. 100MB 파일 10개 vs 10MB 파일 100개 업로드 성능
2. Replication 1, 2, 3별 쓰기 성능
3. 단일 스레드 vs 멀티 스레드 업로드 성능

### 과제 2: 장애 복구 시간 측정

DataNode 장애 발생 시 복구까지 걸리는 시간을 측정하세요:
1. DataNode 중지 시점
2. NameNode가 장애 감지하는 시점
3. Under-replicated 블록 확인 시점
4. DataNode 재시작 후 복구 완료 시점

### 과제 3: 모니터링 대시보드

HDFS 클러스터의 주요 메트릭을 주기적으로 수집하는 스크립트를 작성하세요:
- 1분마다 메트릭 수집
- CSV 파일로 저장
- 용량, 노드 상태, 블록 상태 포함

---

## 성능 튜닝 팁

### 1. Block Size 최적화

```bash
# 기본 블록 크기 확인 (128MB)
hdfs getconf -confKey dfs.blocksize

# 대용량 파일은 큰 블록 크기 사용
# - 적은 메타데이터
# - NameNode 메모리 절약

# 소용량 파일은 작은 블록 크기
# - 병렬 처리 개선
```

### 2. Replication Factor 전략

- **중요 데이터**: Replication = 3 이상
- **임시 데이터**: Replication = 1-2
- **읽기 많은 데이터**: Replication 높게 (병렬 읽기)
- **쓰기 많은 데이터**: Replication 낮게 (쓰기 오버헤드 감소)

### 3. Small Files 문제 해결

- HAR (Hadoop Archive) 사용
- SequenceFile로 병합
- 파일 압축
- HDFS Federation (대규모 환경)

### 4. DataNode 배치 전략

- Rack-aware placement
- Network topology 고려
- DataNode 간 네트워크 대역폭 최적화

---

## 검증 체크리스트

- [ ] TestDFSIO로 읽기/쓰기 성능 벤치마크 완료
- [ ] DataNode 장애를 시뮬레이션하고 복구 확인
- [ ] Under-replicated 블록 감지 및 자동 복구 관찰
- [ ] Safe Mode 동작 이해
- [ ] Replication factor 변경 시 동작 확인
- [ ] 웹 UI 및 CLI로 메트릭 수집 가능
- [ ] 동시 읽기/쓰기 부하 테스트 수행
- [ ] 성능 벤치마크 결과 분석 및 리포트 작성

---

## 마무리

축하합니다! Hadoop HDFS 실습 프로젝트를 완료했습니다.

**학습한 내용**:
1. ✅ Hadoop HDFS 클러스터 구축
2. ✅ HDFS 기본 명령어 마스터
3. ✅ 실전 시나리오 (백업, 로그, 데이터 파이프라인)
4. ✅ 성능 벤치마크 및 장애 테스트

**다음 단계**:
- MapReduce 프로그래밍
- Apache Spark와 HDFS 통합
- YARN (리소스 관리)
- Hive (데이터 웨어하우징)
- HBase (NoSQL 데이터베이스)

**추가 학습 자료**:
- [Hadoop: The Definitive Guide](https://www.oreilly.com/library/view/hadoop-the-definitive/9781491901687/)
- [HDFS Architecture Guide](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [Cloudera Tutorials](https://www.cloudera.com/tutorials.html)

---

**작성일**: 2025-11-17
**최종 수정**: 2025-11-17
**프로젝트 버전**: 1.0
